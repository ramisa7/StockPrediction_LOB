{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkAAHNHmDIUw"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# note: The downloaded data is ready to be fed into any model. \n",
        "# Features, which are used as input variables for training the model, are provided in rows 1 to 144 of each file.\n",
        "# Labels, which represent the target variable that the model aims to predict, are provided from row 145 to the end of each file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# txt to numpy array to csv file\n",
        "# The data is in the form of a .txt file, with each row containing a single data point.\n",
        "# after running this cell, the data will be in the form of a .csv file in your local directory\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# Directory containing the folders & files\n",
        "data_dir = 'BenchmarkDatasets\\BenchmarkDatasets'\n",
        "\n",
        "# Iterate through each folder (auction and noauction)\n",
        "for folder in ['Auction', 'NoAuction']:\n",
        "    folder_path = os.path.join(data_dir, folder)\n",
        "\n",
        "    # Iterate through each normalization setup (z-score)\n",
        "    for normalization_setup in ['1.' + str(folder)+ '_' + 'Zscore']:\n",
        "        normalization_setup_path = os.path.join(folder_path, normalization_setup)\n",
        "       \n",
        "        # Iterate through each type of data (training and testing)\n",
        "        for data_type in [ 'Training',  'Testing']:\n",
        "           \n",
        "            data_type_path = os.path.join(normalization_setup_path, f\"{folder}_Zscore_{data_type}\")\n",
        "            # print what is in the folder\n",
        "            print(os.listdir(data_type_path))\n",
        "            \n",
        "            # train_auction  -> test_auction -> train_noauction -> test_noauction    \n",
        "            for file in os.listdir(data_type_path):\n",
        "                print(file)\n",
        "                # Read the content of the TXT file\n",
        "                with open(os.path.join(data_type_path, file), 'r') as file:\n",
        "                    lines = file.readlines()\n",
        "                    filename = os.path.basename(file.name) \n",
        "                    # Convert the content of the TXT file to a numpy array\n",
        "                    data = np.array([line.strip().split() for line in lines])\n",
        "\n",
        "                    # save the numpy array as a CSV file\n",
        "                    df = pd.DataFrame(data)\n",
        "\n",
        "                    # Save to csv\n",
        "                    df.to_csv(f\"{filename.split('.')[0]}.csv\", index=False, header = False)\n",
        "                    \n",
        "               "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#csv file to particular stock data \n",
        "# input: csv file, stock index\n",
        "# stock index: 0, 1, 2, 3, 4 - each number being a different company stock\n",
        "# output: numpy array of the stock data\n",
        "\n",
        "def extract_stock_from_csv(csv_file, stock_idx):\n",
        "    # Load CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Convert DataFrame to NumPy array\n",
        "    raw_data = df.to_numpy()\n",
        "\n",
        "    # Calculate boundaries\n",
        "    n_boundaries = 4\n",
        "    boundaries = np.sort(\n",
        "        np.argsort(np.abs(np.diff(raw_data[0], prepend=np.inf)))[-n_boundaries - 1:]\n",
        "    )\n",
        "    boundaries = np.append(boundaries, [raw_data.shape[1]])\n",
        "\n",
        "    # Split data\n",
        "    split_data = tuple(raw_data[:, boundaries[i]:boundaries[i + 1]] for i in range(n_boundaries + 1))\n",
        "\n",
        "    return split_data[stock_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_stock_from_csv('Train_Dst_Auction_ZScore_CF_1.csv', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract features & labels & transpose to connect them \n",
        "# input: data (csv file) \n",
        "# output: x (features), y (labels)\n",
        "\n",
        "\n",
        "def extract_feature_label (data):\n",
        "    # Load CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(data)\n",
        "    # pd to numpy\n",
        "    data = df.to_numpy()\n",
        "    \n",
        "    data_length = data.shape[0] - 5\n",
        "\n",
        "    # x is the features, y is the labels\n",
        "    x = data[:data_length, :].T \n",
        "    y = data[-5:, :].T\n",
        "    \n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47342, 143)\n",
            "(47342, 5)\n"
          ]
        }
      ],
      "source": [
        "# Example of one file. \n",
        "# x is the features, y is the labels for all files we work on \n",
        "\n",
        "x, y = extract_feature_label('Train_Dst_Auction_ZScore_CF_1.csv')\n",
        "print(x.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Model "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
